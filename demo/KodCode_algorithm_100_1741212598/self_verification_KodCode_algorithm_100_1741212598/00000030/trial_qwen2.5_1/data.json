{
  "metadata": {
    "prompt_id": "00000030",
    "row_id": 30,
    "seed_ids": [
      97
    ],
    "mode": "algorithm"
  },
  "instruction": "You are given a dataset from the Iris flower classification problem. Implement a logistic regression model to classify the Iris setosa from the Iris versicolor. Use the provided `sigmoid_function` and `cost_function` implementations as a starting point, and implement the logistic regression algorithm without using any external libraries for optimization (e.g., gradient descent).\n\nThe goal is to predict the probability of an Iris flower being in the setosa class based on the sepal length and sepal width.\n\n**Input Format**:\n- A CSV file named `iris.csv` with the following columns: `sepal_length`, `sepal_width`, `class`.\n\n**Output Format**:\n- Print the weights (theta) after training the model.\n- Plot a contour plot showing the decision boundary between setosa and non-setosa flowers.\n\n**Constraints**:\n- The dataset should be normalized before training.\n- Use a learning rate of 0.1 and a maximum of 10,000 iterations.\n\n**Performance Requirements**:\n- The model should converge within the maximum number of iterations.\n\n**Scenario or Context**:\nYou are working on a project to classify Iris flowers based on their sepal length and sepal width. You need to implement a logistic regression model from scratch to predict whether an Iris flower is of the setosa variety.\n\n```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef sigmoid_function(z: float) -> float:\n    return 1 / (1 + np.exp(-z))\n\ndef cost_function(h: np.ndarray, y: np.ndarray) -> float:\n    return float((-y * np.log(h) - (1 - y) * np.log(1 - h)).mean())\n\ndef load_data(filepath: str) -> np.ndarray:\n    data = pd.read_csv(filepath)\n    y = data['class'].apply(lambda x: 1 if x == 'setosa' else 0).values\n    X = data[['sepal_length', 'sepal_width']].values\n    return X, y\n\ndef logistic_reg(alpha, x, y, max_iterations=10000):\n    # Implement the logistic regression algorithm here\n    # ...\n\nif __name__ == \"__main__\":\n    filepath = 'iris.csv'\n    X, y = load_data(filepath)\n    X = (X - X.mean()) / X.std()  # Normalize the data\n    alpha = 0.1\n    theta = logistic_reg(alpha, X, y, max_iterations=10000)\n    print(\"theta: \", theta)\n    # Plot the decision boundary\n    # ...\n```",
  "solution_code": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef sigmoid_function(z: float) -> float:\n    return 1 / (1 + np.exp(-z))\n\ndef cost_function(h: np.ndarray, y: np.ndarray) -> float:\n    return float((-y * np.log(h) - (1 - y) * np.log(1 - h)).mean())\n\ndef load_data(filepath: str) -> np.ndarray:\n    data = pd.read_csv(filepath)\n    y = data['class'].apply(lambda x: 1 if x == 'setosa' else 0).values\n    X = data[['sepal_length', 'sepal_width']].values\n    return X, y\n\ndef logistic_reg(alpha: float, x: np.ndarray, y: np.ndarray, max_iterations: int = 10000) -> np.ndarray:\n    m, n = x.shape\n    x = np.column_stack((np.ones(m), x))  # Add bias term\n    theta = np.zeros(n + 1)\n    \n    for _ in range(max_iterations):\n        z = np.dot(x, theta)\n        h = sigmoid_function(z)\n        gradient = (1 / m) * np.dot(x.T, (h - y))\n        theta -= alpha * gradient\n    \n    return theta\n\nif __name__ == \"__main__\":\n    filepath = 'iris.csv'\n    X, y = load_data(filepath)\n    X = (X - X.mean()) / X.std()  # Normalize the data\n    alpha = 0.1\n    theta = logistic_reg(alpha, X, y, max_iterations=10000)\n    print(\"theta: \", theta)\n\n    # Plot the decision boundary\n    sepal_length = np.linspace(X[:, 1].min(), X[:, 1].max(), 100)\n    sepal_width = -(theta[0] + theta[1] * sepal_length) / theta[2]\n    plt.plot(sepal_length, sepal_width, 'r')\n    \n    # Scatter plot for setosa and non-setosa\n    setosa = X[y == 1]\n    non_setosa = X[y == 0]\n    plt.scatter(setosa[:, 1], setosa[:, 2], c='b', marker='o')\n    plt.scatter(non_setosa[:, 1], non_setosa[:, 2], c='r', marker='x')\n    \n    plt.xlabel('sepal length (normalized)')\n    plt.ylabel('sepal width (normalized)')\n    plt.show()",
  "test_code": "import pytest\nimport numpy as np\n\ndef test_logistic_reg():\n    # Test data\n    X = np.array([[1, 2], [1, 3], [1, 4], [1, 5]])\n    y = np.array([0, 1, 1, 0])\n    \n    # Expected theta\n    expected_theta = np.array([-3, 1, 1])\n    \n    # Run logistic regression\n    theta = logistic_reg(0.1, X, y, max_iterations=10000)\n    \n    # Verify the result is close to the expected theta\n    np.testing.assert_array_almost_equal(theta, expected_theta, decimal=2)\n\ndef test_sigmoid_function():\n    # Test sigmoid function\n    z = 0\n    expected_output = 0.5\n    assert np.isclose(sigmoid_function(z), expected_output)\n\ndef test_cost_function():\n    # Test cost function\n    h = np.array([0.5, 0.5, 0.5])\n    y = np.array([1, 0, 1])\n    expected_output = 0.69314718\n    assert np.isclose(cost_function(h, y), expected_output)\n\ndef test_load_data():\n    # Test loading data\n    filepath = 'iris.csv'\n    X, y = load_data(filepath)\n    assert X.shape[0] == y.shape[0]\n    assert X.shape[1] == 2\n    assert y.shape[0] == X.shape[0]",
  "file_source": "KodCode_questions2sv_algorithm_100_1741212598_sanitized_prepared_results1.jsonl"
}