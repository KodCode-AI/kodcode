{
  "metadata": {
    "prompt_id": "00000011",
    "row_id": 11,
    "seed_ids": [
      824
    ],
    "mode": "algorithm"
  },
  "instruction": "You are tasked with implementing a function to approximate the square root of a given number using Newton's method. The function should handle edge cases and ensure robust performance.\n\n### Function Signature\n\n```python\nfrom typing import Tuple\n\ndef square_root_approximate(\n    a: float, \n    initial_guess: float = 2.0, \n    max_iter: int = 9999, \n    tolerance: float = 1e-14\n) -> Tuple[float, int, bool]:\n    \"\"\"\n    Approximate the square root of a number using Newton's method.\n    \n    Args:\n    a (float): The number to find the square root of.\n    initial_guess (float): The initial guess for the square root. Default is 2.0.\n    max_iter (int): The maximum number of iterations to perform. Default is 9999.\n    tolerance (float): The tolerance level for the approximation. Default is 1e-14.\n    \n    Returns:\n    Tuple[float, int, bool]: \n        - The approximated square root.\n        - The number of iterations performed.\n        - A boolean indicating if the approximation converged within the tolerance.\n    \n    Raises:\n    ValueError: If the input number is negative.\n    \"\"\"\n```\n\n### Constraints\n- The function should handle both positive and negative inputs correctly.\n- `a` must be a non-negative number.\n- The function should return the best approximation within the given tolerance and iteration limit.\n\n### Performance Requirements\n- Ensure the function converges to the correct result within the specified tolerance for all valid inputs.\n- The function should perform no more than `max_iter` iterations.\n\n### Example\n```python\n# Example usage\na = 16\ninitial_guess = 2.0\nmax_iter = 1000\ntolerance = 1e-10\n\nroot, iterations, converged = square_root_approximate(a, initial_guess, max_iter, tolerance)\nprint(root)  # Output: 4.0\nprint(iterations)  # Output: 4\nprint(converged)  # Output: True\n```\n\n### Requirements\n- Implement the logic to handle edge cases and ensure robust performance.\n- Use the provided `fx` and `fx_derivative` functions for the Newton's method.\n- Ensure the function correctly handles negative inputs by raising a `ValueError`.",
  "solution_code": "from typing import Tuple\n\ndef fx(x: float, a: float) -> float:\n    return x**2 - a\n\ndef fx_derivative(x: float) -> float:\n    return 2 * x\n\ndef square_root_approximate(\n    a: float, \n    initial_guess: float = 2.0, \n    max_iter: int = 9999, \n    tolerance: float = 1e-14\n) -> Tuple[float, int, bool]:\n    \"\"\"\n    Approximate the square root of a number using Newton's method.\n    \n    Args:\n    a (float): The number to find the square root of.\n    initial_guess (float): The initial guess for the square root. Default is 2.0.\n    max_iter (int): The maximum number of iterations to perform. Default is 9999.\n    tolerance (float): The tolerance level for the approximation. Default is 1e-14.\n    \n    Returns:\n    Tuple[float, int, bool]: \n        - The approximated square root.\n        - The number of iterations performed.\n        - A boolean indicating if the approximation converged within the tolerance.\n    \n    Raises:\n    ValueError: If the input number is negative.\n    \"\"\"\n    if a < 0:\n        raise ValueError(\"Cannot compute the square root of a negative number.\")\n    \n    x = initial_guess\n    for i in range(max_iter):\n        fx_val = fx(x, a)\n        if abs(fx_val) < tolerance:\n            return (x, i+1, True)\n        \n        df_dx = fx_derivative(x)\n        x_new = x - fx_val / df_dx\n        \n        if abs(x_new - x) < tolerance:\n            return (x_new, i+1, True)\n        \n        x = x_new\n    \n    return (x, max_iter, False)",
  "test_code": "``\nimport pytest\n\ndef test_square_root_approximate_positive():\n    a = 16\n    root, iterations, converged = square_root_approximate(a)\n    assert abs(root - 4.0) < 1e-14\n    assert iterations <= 9999\n    assert converged\n\ndef test_square_root_approximate_zero():\n    a = 0\n    root, iterations, converged = square_root_approximate(a)\n    assert root == 0\n    assert iterations <= 9999\n    assert converged\n\ndef test_square_root_approximate_one():\n    a = 1\n    root, iterations, converged = square_root_approximate(a)\n    assert abs(root - 1.0) < 1e-14\n    assert iterations <= 9999\n    assert converged\n\ndef test_square_root_approximate_negative():\n    a = -1\n    with pytest.raises(ValueError):\n        square_root_approximate(a)\n\ndef test_square_root_approximate_decimal():\n    a = 25.0\n    root, iterations, converged = square_root_approximate(a, initial_guess=2.5)\n    assert abs(root - 5.0) < 1e-14\n    assert iterations <= 9999\n    assert converged\n\ndef test_square_root_approximate_complex_initial_guess():\n    a = 25.0\n    root, iterations, converged = square_root_approximate(a, initial_guess=3.0)\n    assert abs(root - 5.0) < 1e-14\n    assert iterations <= 9999\n    assert converged",
  "file_source": "KodCode_questions2sv_algorithm_100_1741212598_sanitized_prepared_results1.jsonl"
}